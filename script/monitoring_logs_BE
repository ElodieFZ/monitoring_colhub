#!/usr/bin/python3

"""

Monitor colhub BE ingestion

elodief - Oct 2021

"""

import argparse
import pathlib
import logging
import pandas as pd
import numpy as np
from tools import monitoring_logs, utils


def parse_arguments():
    parser = argparse.ArgumentParser(
        description='Products ingested in a DHuS backend for one day.',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('-p', dest='product', default='all',
                        help="Sentinel products to check (S1, S2L2A, S2L1C, S2DEM, S3, S5p) or all for all products")
    parser.add_argument('-d1', dest='yyyymmdd1', required=False,
                        help='First date in range (YYYY/MM/DD). Default is current day.')
    parser.add_argument('-d2', dest='yyyymmdd2', required=False,
                        help='Second date in range (YYYY/MM/DD). Default is first date.')
    parser.add_argument('-cl', dest='colhub_log_dir', required=False, help="BE logs directory.",
                        default='/lustre/storeB/project/ESAcolhub/production-backend-global')
    parser.add_argument('-o', dest='out_file', required=False, help="Output csv results file.",
                        default=pathlib.Path('/home/nbs/colhub/monitoring/BE_global.csv'))
    parser.add_argument('-sl', dest='script_log_dir', required=False, help="script logs directory.",
                        default=pathlib.Path('/home/nbs/colhub/logs'))
    return parser.parse_args()


if __name__ == '__main__':

    args = parse_arguments()

    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)
    logger.addHandler(
        utils.setup_log(pathlib.Path(args.script_log_dir) / f"check_colhub_BE--{pd.to_datetime('today').strftime('%Y%m%d')}.log"))

    # Default start date is current day
    if args.yyyymmdd1 is not None:
        date1 = pd.to_datetime(args.yyyymmdd1, format='%Y/%m/%d')
    else:
        date1 = pd.to_datetime('today').date()

    # Default end date is start date
    if args.yyyymmdd2 is not None:
        date2 = pd.to_datetime(args.yyyymmdd2, format='%Y/%m/%d')
    else:
        date2 = date1

    if args.product == 'all':
        products = ['S1', 'S2L1C', 'S2L2A', 'S2DEM', 'S3', 'S5p']
    else:
        products = [args.product]

    out = []
    for product in products:
        for date in pd.date_range(date1, date2):
            nb, min, max, median, deleted = monitoring_logs.read_logs_dhus(product, date, pathlib.Path(args.colhub_log_dir))
            out.append({'product': product, 'log_date': date, 'nb_ingested': nb,
                        'timeliness_min': min, 'timeliness_max': max, 'timeliness_median': median, 'products_deleted': deleted})

    if args.out_file:
        pd.DataFrame(out).to_csv(args.out_file, index=False, mode='a', header=None)







